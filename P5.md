# Practical 5: Kafka and Spark Structured Streaming

1. Start Kafka-related services using user hduser account

   i. Start HDFS
      ~~~bash
      hduser@MyPC:~$ start-dfs.sh
      ~~~

   ii. Start YARN
      ~~~~bash
      hduser@MyPC:~$ start-yarn.sh
      ~~~~

   iii. Start Zookeeper
      ~~~~bash
      hduser@MyPC:~$ zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties &
      ~~~~
      > Note: You will see a stream of output. Press <enter> as the ampersand (&) indicates that the service will run in the background.
      > 
      > hduser@MyPC:~$ jps
      >                                       
      > 7110 Jps
      > 
      > 4454 ResourceManager
      > 
      > 3640 SecondaryNameNode
      > 
      > 3402 DataNode
      > 
      > 5964 QuorumPeerMain
      > 
      > 4605 NodeManager
      > 
      > 3213 NameNode
      > 
      >Note: Wait for about 30 seconds before performing the next step.

   iv. Start Kafka
      ~~~~bash
      $ kafka-server-start.sh $KAFKA_HOME/config/server.properties &
      ~~~
      > Note: You will see a stream of output. Press <enter> as the ampersand (&) indicates that the service will run in the background.
      >
      > $ jps
      >
      > 7110 Jps
      >
      > 4454 ResourceManager
      >
      > 3640 SecondaryNameNode
      >
      > 3402 DataNode
      >
      > 6506 Kafka
      >
      > 5964 QuorumPeerMain
      >
      > 4605 NodeManager
      >
      > 3213 NameNode  

~~~ As the user student ~~~ 
Add Kafka variables and path to profile
Open the profile file
$ nano ~/.profile

And add the following lines at the end of the file.
export KAFKA_HOME=/home/hduser/kafka
export PATH=$PATH:$KAFKA_HOME/bin

Then save the file and exit the editor.

Source the file:
$ source ~/.profile
Managing Topics Using the Terminal
Create topics called test, cats, meow and wiki-changes:
$ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic test
$ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic cats
$ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic meow
$ kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic wiki-changes

List all available topics:
$ kafka-topics.sh --list --bootstrap-server localhost:9092

Describe a Kafka topic:
$ kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic test

To delete a Kafka topic:
$ kafka-topics.sh --delete --bootstrap-server localhost:9092 --topic test




~~~ As the user student ~~~ 
Simulation of Producer and Consumer Terminals
Assume the existing terminal is the Producer. To simulate a Consumer terminal, open another terminal (e.g., either by launching wsl in another PowerShell terminal or by opening a terminal using jupyterlab. Then, carry out the steps according to the sequence shown in the table below:
Note: Use different PCs and individual users for the Producer and Consumer terminals.

Producer terminal
Consumer terminal


List all available topics.
Send a few messages under the topic test:
$ kafka-console-producer.sh --broker-list localhost:9092 --topic test
A prompt (>) should appear for you to input your messages. For example, type in the following messages:
> This is the 1st test message
> This is the 2nd test message
To consume messages, start a console-based consumer:
$ kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

Observe the messages previously sent by the Producer appearing (i.e., being consumed by this Consumer).
Send a few more messages:
> This is the 3rd test message
> This is the 4th test message 
> This is the 5th test message 
To quit, press <Ctrl><C>.
Messages are stored by default in the /tmp/kafka-logs/ directory or set as the value of log.dirs in the  config/server.properties file.
Observe the new messages arriving in this Consumer terminal.




To examine the incoming messages, check the Kafka log directory:
$ ls -l /tmp/kafka-logs/test-0
student@PC25:~$ ls -l /tmp/kafka-logs/test-0
total 12
-rw-r--r-- 1 hduser hduser 10485760 Jun  6 15:58 00000000000000000000.index
-rw-r--r-- 1 hduser hduser      374 Jun  6 16:02 00000000000000000000.log
-rw-r--r-- 1 hduser hduser 10485756 Jun  6 15:58 00000000000000000000.timeindex
-rw-r--r-- 1 hduser hduser        8 Jun  6 15:58 leader-epoch-checkpoint
-rw-r--r-- 1 hduser hduser       43 Jun  6 15:58 partition.metadata

$ kafka-run-class.sh kafka.tools.DumpLogSegments --deep-iteration --print-data-log --files /tmp/kafka-logs/test-0/00000000000000000000.log
Note: Follow the file name of the *.log file that appears in your directory.



~~~ As the user student ~~~ 
Accessing Kafka in Python Code
Install kafka-python 
kafka-python-ng
kafka-python API modules
Activate your venv and install kafka-python
 		$ pip install kafka-python-ng

Note: Use different terminals for the Producer and Consumer terminals.
Run the Consumer code
$ python kafka-python-consumer.py

Run the Producer Code
To simulate a Producer terminal, open another instance of terminal
Activate your virtual environment
Run the the producer code:
$ python kafka-python-producer.py
Return to your Consumer terminal and observe the outputs.

~~~ As the user hduser ~~~
Stopping Kafka-related services

Stop Kafka
$ kafka-server-stop.sh
Note: Wait for about 30 seconds before performing the next step.


Stop Zookeeper
$ zookeeper-server-stop.sh
Note: Wait for about 30 seconds before performing the next step.


Stop YARN
$ stop-yarn.sh


Stop HDFS
$ stop-dfs.sh
