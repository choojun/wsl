# PRACTICAL 2: Hadoop Distributed File System (HDFS)

1. Launch the setup Ubuntu-xx.xx distro with the PowerShell, refer to step 1 of P1.

2. Login as the user hduser, start HDFS and YARN 

   Start the HDFS and YARN services, and check the services currently running, use the jps command.
   > Note that these actions should be performed AFTER completing steps 1 to 5 in P0.
   
3. Create User Directories in HDFS

   3.1 Create a HDFS user directory for student:
      ~~~bash
      hduser@MyPC:~$ hdfs dfs -mkdir /user/student
      ~~~
      > Note that a message indicating the target directory already exists should be observed, as its creation was completed in Step 2 of P0.

    3.2 Change ownership for the created directory:
      ~~~bash
      hduser@MyPC:~$ hdfs dfs -chown student:hduser /user/student
      ~~~
      > We also have done the same same command in step 3 of P0.
      > 
      > Note that changing HDFS file permissions are similar to Linux file permissions. **Example**, to change the permission of the file shakespeare.txt to 664. First, download the shakespeare.txt file. Next, upload the file from Ubuntu to HDFS, adhering to steps 5.2 and 5.3, respectively. Only then proceed with the command as outlined below.
      > ~~~bash
      > hduser@MyPC:~$ hdfs dfs -chmod 664 shakespeare.txt
      > ~~~
      > where 664 is an octal representation of the flags to set for the permission triple.
      > 
      > The above statement  changes the permissions to -rw-rw-r--:
      > 
      > 6 is 110, which means read and write, but not execute.
      > 
      > 7 is 111, which means complete permissions.
      > 
      > 4 is 100, which means read-only.

4. Switch to user student
   ~~~bash
   hduser@MyPC:~$ su - student
   student@MyPC:~$
   ~~~

5. HDFS Basic File System Operations

   5.1 See the available commands in the dfs shell
     ~~~bash
     student@MyPC:~$ hdfs dfs -help
     ~~~

     **Note that if the above command fails to execute, you'll need to prepare the user student account environment by following these steps.**

     i. Change the access mode for home directory of user hduser account. 
      ~~~bash
      student@MyPC:~$ sudo chmod 755 /home/hduser
      ~~~
      > Note that this steps is done for the teaching-learning purposes, and it is not recommended for production use.

     ii. Edit the file .profile of user student by adding the following lines (IF NOT EXIST) at the end of file
      ~~~bash
      student@MyPC:~$ nano ~/.profile 
      ~~~
      > export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
      > 
      > export HADOOP_HOME=/home/hduser/hadoop3
      > 
      > export PATH=$PATH:$HADOOP_HOME/bin
      >
      
     iii. Source the file .profile of user student, and retry the failed command above.
      ~~~bash
      student@MyPC:~$ source ~/.profile
      ~~~
      
   5.2 Download the shakespeare.txt file from Google Drive into your local file system (Ubuntu xx.xx)
     ~~~bash
     student@MyPC:~$ wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=122PnuKaSaA_OyYOKnxQOdlMc5awdyf5v' -O shakespeare.txt
     ~~~
     > Remember to confirm that the above action is successful.

   5.3 Copy the downloaded file shakespeare.txt from the local file system to HDFS
     ~~~bash
     student@MyPC:~$ hdfs dfs -put shakespeare.txt shakespeare.txt
     ~~~
     > Remember to confirm that the above action is successful.

   5.4 Read the contents of the file in HDFS using the cat command, and then pipe the output to less in order to view the contents of the remote file.  
     ~~~bash
     student@PC25:~$ hdfs dfs -cat shakespeare.txt | less 
     ~~~
     > Note: use the arrow keys to navigate the file. Type q to quit.

   5.5 Copy the file from HDFS to the local file system and rename it as shakespeare-dfs.txt.
     ~~~bash
     student@MyPC:~$ hdfs dfs -get shakespeare.txt ./shakespeare-dfs.txt
     ~~~
     > Remember to confirm that the above action is successful.

6. To end your practical sessions

   6.1 Logout from the student account
     ~~~bash
     student@MyPC:~$ exit
     hduser@PC25:~$ 
     ~~~
     
    6.2 Login as the user hduser, terminate the YARN service.
     ~~~bash
     hduser@MyPC:~$ stop-yarn.sh
     hduser@MyPC:~$ jps
     hduser@MyPC:~$ 
     ~~~
     > Suppose that services ResourceManager and NodeManager will be terminated (disappearing after the command of stop-yarn.sh). 

    6.3 Login as the user hduser, terminate the HDFS service.
     ~~~bash
     hduser@MyPC:~$ stop-dfs.sh
     hduser@MyPC:~$ jps
     hduser@MyPC:~$ 
     ~~~
     > Suppose that services NameNode, SecondaryNameNode and DataNode will be terminated (disappearing after the command of stop-dfs.sh). 

    6.4 Logout from user hduser account.
     ~~~bash
     hduser@MyPC:~$ exit
     PS C:\Users\choojun> 
     ~~~

    6.5 Terminate the WSL instance.
     ~~~bash
     PS C:\Users\choojun> exit
     ~~~
     > Suppose that the PowerShell window will be closed.
     

# Try Other HDFS Commands

Recall that the HDFS shell commands are similar to POSIX-like commands and invoked using:
~~~bash
$ hdfs dfs <args> <command>
~~~

* cat
* chgrp
* chmod
* chown
* cp
* du
* ls
* mkdir
* mv
* rm
* stat
* tail 


