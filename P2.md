# PRACTICAL 2: Hadoop Distributed File System (HDFS)

1. Launch the setup Ubuntu-xx.xx distro with the PowerShell with the command:
   ~~~bash
   PS C:\Users\TARUMT> wsl ~
   hduser@MyPC:~$ 
   ~~~

2. Login as the user hduser, start HDFS and YARN 

   2.1 Start the HDFS service, and check the services currently running, use the jps command.
       ~~~bash
       hduser@MyPC:~$ start-dfs.sh
       Starting namenodes on [localhost]
       Starting datanodes
       Starting secondary namenodes [MyPC]

       hduser@MyPC:~$ jps
       1392 Jps
       1114 SecondaryNameNode
       876 DataNode
       685 NameNode
       ~~~

    2.2 Start the YARN service
      ~~~bash
      hduser@MyPC:~$ start-yarn.sh
      Starting resourcemanager
      Starting nodemanagers
      
      hduser@MyPC:~$ jps
      2112 Jps
      1696 NodeManager
      1542 ResourceManager
      1114 SecondaryNameNode
      876 DataNode
      685 NameNode
      ~~~
   
      > Note that the following actions have already been completed in the setup of distro:
      > Create the directories named user and tmp in the distributed file system: 
      > The /user directory is where all Hadoop usersâ€™ home directories will be created later on.
      > ~~~bash
      > hduser@MyPC:~$ hdfs dfs -mkdir /user
      > hduser@MyPC:~$ hdfs dfs -mkdir /tmp
      > ~~~
      > 
      > Give full permissions for all users to the tmp directory:
      > ~~~bash
      > hduser@MyPC:~$ hdfs dfs -chmod -R 777 /tmp
      > ~~~
   
3. Create User Directories in HDFS

   3.1 Create a HDFS user directory for student:
      ~~~bash
      hduser@MyPC:~$ hdfs dfs -mkdir /user/student
      ~~~

    3.2 Change ownership for the newly created directory:
      ~~~bash
      hduser@PC25:~$ hdfs dfs -chown student:hduser /user/student
      ~~~
      
      > HDFS file permissions are similar to Linux file permissions. 
      > E.g., to change the permission of the file shakespeare.txt to 664:
      > ~~~bash
      > $ hdfs dfs -chmod 664 shakespeare.txt
      > ~~~
      > where 664 is an octal representation of the flags to set for the permission triple.
      > 
      > The above statement  changes the permissions to -rw-rw-r--:
      > 
      > 6 is 110, which means read and write, but not execute.
      > 
      > 7 is 111, which means complete permissions.
      > 
      > 4 is 100, which means read-only.

4. Switch to user student
   ~~~bash
   hduser@MyPC:~$ su - student
   student@MyPC:~$
   ~~~

5. HDFS Basic File System Operations

   5.1 See the available commands in the dfs shell
     ~~~bash
     student@MyPC:~$ hdfs dfs -help
     ~~~

     If the above command fails to execute, you'll need to prepare the user student account environment by following these steps.

     i. Copy the access mode for home directory of user hduser account. This steps is for teaching-learning purposes, and it is not recommended for production use.
      ~~~bash
      student@MyPC:~$ sudo chmod 755 /home/hduser
      ~~~

     ii. Edit the file .profile of user student by adding the following lines at the end of file
      ~~~bash
      student@MyPC:~$ nano ~/.profile 
      ~~~
      > export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
      >
      > export HADOOP_HOME=/home/hduser/hadoop3
      >
      > export PATH=$PATH:$HADOOP_HOME/bin

     iii. Source the file .profile of user student
      ~~~bash
      student@MyPC:~$ source ~/.profile
      ~~~
      
   5.2 Download the shakespeare.txt file from Google Drive into your local file system (Ubuntu xx.xx)
     ~~~bash
     student@MyPC:~$ wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=122PnuKaSaA_OyYOKnxQOdlMc5awdyf5v' -O shakespeare.txt
     ~~~
     > Remember to confirm that the above action is successful.

   5.3 Copy the downloaded file shakespeare.txt from the local file system to HDFS
     ~~~bash
     student@MyPC:~$ hdfs dfs -put shakespeare.txt shakespeare.txt
     ~~~
     > Remember to confirm that the above action is successful.

   5.4 Read the contents of the file in HDFS using the cat command, and then pipe the output to less in order to view the contents of the remote file.  
     ~~~bash
     student@PC25:~$ hdfs dfs -cat shakespeare.txt | less 
     ~~~
     > Note: use the arrow keys to navigate the file. Type q to quit.

   5.5 Copy the file from HDFS to the local file system and rename it as shakespeare-dfs.txt.
     ~~~bash
     student@MyPC:~$ hdfs dfs -get shakespeare.txt ./shakespeare-dfs.txt
     ~~~
     > Remember to confirm that the above action is successful.

7. To end your practical sessions

   6.1 Logout from the student account
     ~~~bash
     student@MyPC:~$ exit
     hduser@PC25:~$ 
     ~~~
     
    6.2 Login as the user hduser, terminate the YARN service.
     ~~~bash
     hduser@MyPC:~$ stop-yarn.sh
     hduser@MyPC:~$ jps
     hduser@MyPC:~$ 
     ~~~
     > Suppose that services ResourceManager and NodeManager will be terminated (disappearing after the command of stop-yarn.sh). 

    6.3 Login as the user hduser, terminate the HDFS service.
     ~~~bash
     hduser@MyPC:~$ stop-dfs.sh
     hduser@MyPC:~$ jps
     hduser@MyPC:~$ 
     ~~~
     > Suppose that services NameNode, SecondaryNameNode and DataNode will be terminated (disappearing after the command of stop-dfs.sh). 

    6.4 Logout from user hduser account.
     ~~~bash
     hduser@MyPC:~$ exit
     PS C:\Users\choojun> 
     ~~~

    6.5 Terminate the WSL instance.
     ~~~bash
     PS C:\Users\choojun> exit
     ~~~
     > Suppose that the PowerShell window will be closed.
     

# Try Other HDFS Commands

Recall that the HDFS shell commands are similar to POSIX-like commands and invoked using:
~~~bash
$ hdfs dfs <args> <command>
~~~

* cat
* chgrp
* chmod
* chown
* cp
* du
* ls
* mkdir
* mv
* rm
* stat
* tail 


