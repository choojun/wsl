# Pratical 0: Required preparatory steps for each practical session (applicable to laboratory PC or following each restoration of the WSL distro)

0. After restoring the WSL distro, launch the setup Ubuntu-xx.xx distro with the PowerShell with the command:
    ~~~bash
    PS C:\Users\TARUMT> wsl -l -v
    PS C:\Users\TARUMT> wsl –d <distro name> -u hduser
    hduser@MyPC:~$ 
    ~~~
    > Proceed as follows if the required distribution is the default WSL distro
    ~~~bash
    PS C:\Users\TARUMT> wsl ~
    hduser@MyPC:~$ 
    ~~~

1.  Start HDFS and YARN as the hduser user. You should see six services running in the background (use the jps command). 
    ~~~bash
    hduser@MyPC:~$ cd ~/hadoop3
    hduser@MyPC:~$ sbin/start-dfs.sh
    hduser@MyPC:~$ sbin/start-yarn.sh
    hduser@MyPC:~$ jps
    ~~~
    > Using the jps command, six services are visible (order is not important): Jps, DataNode, NameNode, SecondaryNameNode, NodeManager, and ResourceManager processes.
    > 
    > Source: Step 2 of Section D and Step 1 of Section Z at URL https://choojun.github.io/wsl
2. Create a HDFS user directory for student as well as other needed directories with correct permisson of assess
     ~~~bash
     hduser@MyPC:~$ hdfs dfs -mkdir /user
     hduser@MyPC:~$ hdfs dfs -mkdir /user/student
     hduser@MyPC:~$ hdfs dfs -mkdir /tmp
     hduser@MyPC:~$ hdfs dfs -chmod -R 777 /tmp
     ~~~
     > Note that the /user directory is where all Ubuntu users’ home directories will be created later on, including tarumt, hduser and student.

3. Change ownership for the newly created student directory to student:hduser
     ~~~bash
     hduser@MyPC:~$ hdfs dfs -chown student:hduser /user/student
     ~~~

4. Switch to student user, and authorise student user to access the home directory of user hduser account (specifically on those setup software)
     ~~~bash
     hduser@MyPC:~$ su - student
     student@MyPC:~$ sudo chmod 755 /home/hduser
     ~~~

5. Add (IF NOT EXIST) / Edit (IF ANY CHANGES) / Ensure related system environment variables to student’s profile
 
   5.1 Edit the file ~/.profile
     ~~~bash
     student@MyPC:~$ nano ~/.profile
     ~~~
     
   5.2 Add the following environment variables to the end of the file:
     ~~~bash
     export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
     export HADOOP_HOME=/home/hduser/hadoop3
     export PATH=$PATH:$HADOOP_HOME/bin
     
     export SPARK_HOME=/home/hduser/spark
     export PATH=$PATH:$SPARK_HOME/bin
     export PYSPARK_PYTHON=/home/student/de-prj/de-venv/bin/python

     export KAFKA_HOME=/home/hduser/kafka
     export PATH=$PATH:$KAFKA_HOME/bin

     export HBASE_HOME=/home/hduser/hbase
     export PATH=$HBASE_HOME/bin:$PATH
     
     ~~~
     > The file can be saved by pressing Ctrl-X and subsequently entering Y.
     
   5.3 Source the ~/.profile file.
     ~~~bash
     student@MyPC:~$ source ~/.profile
     ~~~

6. Copy required files for practical activities

   6.1 Create a project directory (e.g., de-prj)
     ~~~bash
     student@MyPC:~$ mkdir de-prj
     ~~~

   6.2 Copy the contents of the sample_code folder from your Windows 11's drive (e.g. C:\ drive) to the distro’s de-prj directory in the local OS (i.e. Ubuntu):
     ~~~bash
     student@MyPC:~$ cp -r /mnt/c/sample_code/* /home/student/de-prj/
     ~~~
     > Note that download the sample_code from Google Classroom.

   6.3 Copy the sample_data folder from your Windows 11’s drive (e.g.  C:\ drive) to the distro's home directory:
     ~~~bash
     student@MyPC:~$ cp -r /mnt/c/sample_data /home/student/
     ~~~
     > Note that download the sample_data from Google Classroom.

   6.4 Put the sample_data folder into HDFS as a directory named data:
     ~~~bash
     student@MyPC:~$ hdfs dfs -put sample_data data
     ~~~

7. Create a virtual environment and setup the virtual environment for Python programming with JupyterLab

   7.1 Create a project directory (e.g., de-prj)
     ~~~bash
     student@MyPC:~$ mkdir de-prj
     ~~~
     It is advisable to utilize distinct directories for each project development
     
   7.2 Create a virtual environment for your project (e.g., de-venv):
     ~~~bash
     student@MyPC:~$ python3 -m venv de-prj/de-venv
     student@MyPC:~$ de-prj/de-venv/bin/python -m pip install -U --quiet pip wheel setuptools 
     student@MyPC:~$ de-prj/de-venv/bin/python -m pip install -U --quiet ipykernel
     student@MyPC:~$ de-prj/de-venv/bin/python -m ipykernel install --user --name "de-venv" --display-name  "de-venv"
     ~~~
     > **Recommendation**: Always create a separated virtual environment for your new project.
     
   7.3 Activate the virtual environment
     ~~~bash
     student@MyPC:~$ source de-prj/de-venv/bin/activate
     ~~~
     > Once you have finished working on your project, it’s a good habit to deactivate its venv. By deactivating, you leave the virtual environment. Note that without deactivating your venv, all other Python code you execute, even if it is outside your project directory, will also run inside the venv.
     >
     > Use command:
     > 
     > student@MyPC:~$ deactivate
     
   7.4 Install packages
     ~~~bash
     (de-venv) student@MyPC:~$ pip install numpy pyspark
     ~~~
     > It will take a while for downloading and installation activities.
     
   7.5 Run the JupyterLab service
     ~~~bash
     (de-venv) student@MyPC:~$ jupyter lab
     ~~~
     > Use Ctrl-c to terminate the running JupyterLab service.



# Trouble-shooting

1. Port 22 connection refused
   1.1 Check whether your ssh service is running:
    ~~~bash
    $ service ssh status
    ~~~

   1.2 If not running, start the ssh service:
     ~~~bash
     $ sudo service ssh start
     ~~~

2. To install WSL using Windows Features

   https://techcommunity.microsoft.com/t5/windows-11/how-to-install-the-linux-windows-subsystem-in-windows-11/m-p/2701207

3. How to format Namenode of Hadoop?

   This step must be performed if the Namenode service is not observed after the DFS and YARN services have been initiated. Please note that all data stored in HDFS will be irrevocably lost upon formatting. All services must be stopped (verified with the jps command) before issuing the formatting command.

   Refer to Step 11 of Section E7 at https://choojun.github.io/wsl_hadoop for the command details.

4. Copying files - **Applicable for P2 and beyond**

   i. To copy from Windows to WSL
   > Syntax: sudo cp -r /mnt/<source drive>/[source path in Windows] [destination path in Ubuntu].
   > 
   > Example: $ sudo cp -r /mnt/c/de /home/student

   ii. To copy from WSL to Windows.
   > 
   > Example 1:
   > $ sudo cp -r /home/student/de-prj /mnt/c/
   > > Please ensure that you have the source directory, i.e. /home/student/de-prj, before performing this command.
   > 
   > Example 2:
   > $ sudo cp -r /home/hduser/wordcount /mnt/c/de-prj/
   > > Please ensure that you have the source directory, i.e. /home/hduser/wordcount, before performing this command.


5. To put (upload) the data folder from the student’s home directory to HDFS - **Applicable for P2 and beyond**
   ~~~bash
   $ hdfs dfs -put /home/student/de/data .
   ~~~
   > Please ensure that you have the source directory, i.e. /home/student/de/data, before performing this command.

