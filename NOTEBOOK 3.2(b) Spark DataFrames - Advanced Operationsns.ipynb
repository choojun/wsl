{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edf3357",
   "metadata": {
    "id": "0edf3357"
   },
   "source": [
    "# NOTEBOOK 3.2(b) Spark DataFrames - Advanced Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3383b1a",
   "metadata": {
    "id": "c3383b1a"
   },
   "source": [
    "## 0. Preparations\n",
    "\n",
    "Before starting this practical, ensure that the json data file named **nyt2.json** exists in the HDFS directory named **data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b559e23",
   "metadata": {
    "id": "3b559e23"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from datetime import date, timedelta, datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d62f2",
   "metadata": {
    "id": "9a0d62f2"
   },
   "source": [
    "## 1. Initialize SparkSession\n",
    "\n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html?highlight=sparksession#pyspark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32873987",
   "metadata": {
    "id": "32873987",
    "outputId": "698a7156-2cc3-4e8b-b925-9b53268756ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/12 14:15:42 WARN Utils: Your hostname, PC25. resolves to a loopback address: 127.0.1.1; using 192.168.76.195 instead (on interface eth0)\n",
      "25/06/12 14:15:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/12 14:15:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"PysparkExample\")\\\n",
    ".config('spark.executor.instances', '2')\\\n",
    ".config('spark.executor.memory', '1g')\\\n",
    ".config('spark.executor.cores', '4')\\\n",
    ".config (\"spark.sql.shuffle.partitions\", \"50\")\\\n",
    ".config(\"spark.driver.maxResultSize\",\"5g\")\\\n",
    ".config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5964c6db-1aa7-4ec9-b830-781634b6fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.executor.cores: 4\n",
      "spark.rdd.compress: True\n",
      "spark.executor.memory: 1g\n",
      "spark.app.id: local-1749708944122\n",
      "spark.app.submitTime: 1749708943412\n",
      "spark.master: local[*]\n",
      "spark.sql.execution.arrow.pyspark.enabled: true\n",
      "spark.driver.host: 192.168.76.195\n",
      "spark.driver.maxResultSize: 5g\n",
      "spark.driver.port: 39845\n",
      "spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.executor.id: driver\n",
      "spark.submit.pyFiles: \n",
      "spark.sql.shuffle.partitions: 50\n",
      "spark.executor.instances: 2\n",
      "spark.submit.deployMode: client\n",
      "spark.app.name: PysparkExample\n",
      "spark.serializer.objectStreamReset: 100\n",
      "spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.ui.showConsoleProgress: true\n",
      "spark.app.startTime: 1749708943509\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "conf = sc.getConf()\n",
    "\n",
    "# Get all Spark parameter values as a list of key-value pairs\n",
    "all_configs = conf.getAll()\n",
    "\n",
    "# Print them\n",
    "for key, value in all_configs:\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6f31f7-c19c-4f29-ae68-b80b6df3aa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective spark.executor.instances: 2\n",
      "Effective spark.executor.memory: 1g\n",
      "Effective spark.executor.cores: 4\n"
     ]
    }
   ],
   "source": [
    "conf_dict = dict(sc.getConf().getAll())\n",
    "\n",
    "print(f\"Effective spark.executor.instances: {conf_dict.get('spark.executor.instances')}\")\n",
    "print(f\"Effective spark.executor.memory: {conf_dict.get('spark.executor.memory')}\")\n",
    "print(f\"Effective spark.executor.cores: {conf_dict.get('spark.executor.cores')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad821760",
   "metadata": {
    "id": "ad821760"
   },
   "source": [
    "## 2. Spark DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db899b89",
   "metadata": {
    "id": "db899b89"
   },
   "source": [
    "### 2.1 Create Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9458da8c",
   "metadata": {
    "id": "9458da8c",
    "outputId": "40462e82-5687-4499-ce9f-9be95569996a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+---------+-------------+\n",
      "|                 _id|  amazon_product_url|         author| bestsellers_date|         description|        price|   published_date|    publisher|rank|rank_last_week|    title|weeks_on_list|\n",
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+---------+-------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|  Dean R Koontz|{{1211587200000}}|Odd Thomas, who c...|   {NULL, 27}|{{1212883200000}}|       Bantam| {1}|           {0}|ODD HOURS|          {1}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|Stephenie Meyer|{{1211587200000}}|Aliens have taken...|{25.99, NULL}|{{1212883200000}}|Little, Brown| {2}|           {1}| THE HOST|          {3}|\n",
      "+--------------------+--------------------+---------------+-----------------+--------------------+-------------+-----------------+-------------+----+--------------+---------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Spark dataframe from the json data file\n",
    "df = spark.read.json(\"data/nyt2.json\")\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31372d",
   "metadata": {
    "id": "9d31372d"
   },
   "source": [
    "### 2.2 Inspecting the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5be2c5",
   "metadata": {
    "id": "3a5be2c5",
    "outputId": "5f390018-a1c7-47b1-dc21-f05410b33466"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the type of df\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a83bb4f",
   "metadata": {
    "id": "7a83bb4f",
    "outputId": "aa0d2a04-0b3e-4ba6-9e6f-7dc15e52d196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame column names and data types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('_id', 'struct<$oid:string>'),\n",
       " ('amazon_product_url', 'string'),\n",
       " ('author', 'string'),\n",
       " ('bestsellers_date', 'struct<$date:struct<$numberLong:string>>'),\n",
       " ('description', 'string'),\n",
       " ('price', 'struct<$numberDouble:string,$numberInt:string>'),\n",
       " ('published_date', 'struct<$date:struct<$numberLong:string>>'),\n",
       " ('publisher', 'string'),\n",
       " ('rank', 'struct<$numberInt:string>'),\n",
       " ('rank_last_week', 'struct<$numberInt:string>'),\n",
       " ('title', 'string'),\n",
       " ('weeks_on_list', 'struct<$numberInt:string>')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the dataframe column names and data types\n",
    "print(\"DataFrame column names and data types\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e226f9",
   "metadata": {
    "id": "f7e226f9",
    "outputId": "07cf7bb9-f8a9-4c3e-8611-73b0ef8934e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/12 14:15:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------+--------------------+---------+------------------+\n",
      "|summary|  amazon_product_url|         author|         description|publisher|             title|\n",
      "+-------+--------------------+---------------+--------------------+---------+------------------+\n",
      "|  count|               10195|          10195|               10195|    10195|             10195|\n",
      "|   mean|                NULL|           NULL|                NULL|     NULL|1877.7142857142858|\n",
      "| stddev|                NULL|           NULL|                NULL|     NULL| 370.9760613506458|\n",
      "|    min|http://www.amazon...|        AJ Finn|                    |      ACE|  10TH ANNIVERSARY|\n",
      "|    max|https://www.amazo...|various authors|’Tis for the Rebe...|allantine|               ZOO|\n",
      "+-------+--------------------+---------------+--------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute basic statistics for the dataframe columns.\n",
    "print(\"\\nSummary statistics\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195687de",
   "metadata": {
    "id": "195687de",
    "outputId": "f46d6c42-f531-444c-fefe-004584ec937f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'amazon_product_url',\n",
       " 'author',\n",
       " 'bestsellers_date',\n",
       " 'description',\n",
       " 'price',\n",
       " 'published_date',\n",
       " 'publisher',\n",
       " 'rank',\n",
       " 'rank_last_week',\n",
       " 'title',\n",
       " 'weeks_on_list']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns columns of dataframe\n",
    "print(\"\\nDataFrame columns\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "778edf5d",
   "metadata": {
    "id": "778edf5d",
    "outputId": "8e5e0e5c-80bf-42cd-d7e2-f50d2d0cbafd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of rows in the dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts the number of rows in dataframe\n",
    "print(\"\\nNumber of rows in the dataframe\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e10f2ded",
   "metadata": {
    "id": "e10f2ded",
    "outputId": "fb7c23c0-d786-4169-871e-033843e98490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of distinct rows in the dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10195"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts the number of distinct rows in dataframe\n",
    "print(\"\\nNumber of distinct rows in the dataframe\")\n",
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1660787f",
   "metadata": {
    "id": "1660787f",
    "outputId": "6e464650-7c0e-47c5-92c5-1c460a3f47b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Physical and logical dataframe plans\n",
      "== Physical Plan ==\n",
      "FileScan json [_id#8,amazon_product_url#9,author#10,bestsellers_date#11,description#12,price#13,published_date#14,publisher#15,rank#16,rank_last_week#17,title#18,weeks_on_list#19] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[hdfs://localhost:9000/user/student/data/nyt2.json], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_id:struct<$oid:string>,amazon_product_url:string,author:string,bestsellers_date:struct<$d...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints plans including physical and logical\n",
    "print(\"\\nPhysical and logical dataframe plans\")\n",
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73de09",
   "metadata": {
    "id": "0b73de09"
   },
   "source": [
    "## 3. Advanced Spark DataFrame Operations\n",
    "https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html\n",
    "\n",
    "### 3.1 when() Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc17800",
   "metadata": {
    "id": "fbc17800",
    "outputId": "38d5d8ec-20c9-4164-a5a8-a83784d30f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------------------------------------+\n",
      "|               title|CASE WHEN (NOT (title = ODD HOURS)) THEN 1 ELSE 0 END|\n",
      "+--------------------+-----------------------------------------------------+\n",
      "|           ODD HOURS|                                                    0|\n",
      "|            THE HOST|                                                    1|\n",
      "|LOVE THE ONE YOU'...|                                                    1|\n",
      "|           THE FRONT|                                                    1|\n",
      "|               SNUFF|                                                    1|\n",
      "|SUNDAYS AT TIFFANY’S|                                                    1|\n",
      "|        PHANTOM PREY|                                                    1|\n",
      "|          SWINE NOT?|                                                    1|\n",
      "|     CARELESS IN RED|                                                    1|\n",
      "|     THE WHOLE TRUTH|                                                    1|\n",
      "+--------------------+-----------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show title and assign 0 or 1 depending on title\n",
    "df.select(\"title\", when(df.title != 'ODD HOURS', 1).otherwise(0)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b2de8",
   "metadata": {
    "id": "c14b2de8"
   },
   "source": [
    "### 3.2 isin Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76117c83",
   "metadata": {
    "id": "76117c83",
    "outputId": "191c2437-c9fd-4f26-df28-fc49ea539ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+-----------------+--------------------+-------------+-----------------+------------+----+--------------+--------------------+-------------+\n",
      "|                 _id|  amazon_product_url|       author| bestsellers_date|         description|        price|   published_date|   publisher|rank|rank_last_week|               title|weeks_on_list|\n",
      "+--------------------+--------------------+-------------+-----------------+--------------------+-------------+-----------------+------------+----+--------------+--------------------+-------------+\n",
      "|{5b4aa4ead3089013...|http://www.amazon...| Emily Giffin|{{1211587200000}}|A woman's happy m...|{24.95, NULL}|{{1212883200000}}|St. Martin's| {3}|           {2}|LOVE THE ONE YOU'...|          {2}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...|John Sandford|{{1211587200000}}|The Minneapolis d...|{26.95, NULL}|{{1212883200000}}|      Putnam| {7}|           {4}|        PHANTOM PREY|          {3}|\n",
      "|{5b4aa4ead3089013...|http://www.amazon...| Emily Giffin|{{1212192000000}}|A woman’s happy m...|{24.95, NULL}|{{1213488000000}}|St. Martin’s| {4}|           {3}|LOVE THE ONE YOU'...|          {3}|\n",
      "+--------------------+--------------------+-------------+-----------------+--------------------+-------------+-----------------+------------+----+--------------+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[df.author.isin(\"John Sandford\", \"Emily Giffin\")].show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed95c85",
   "metadata": {
    "id": "bed95c85"
   },
   "source": [
    "### 3.3 like Operation\n",
    "The % character is used to filter out all titles containing the word \" THE \" word.\n",
    "To match an entire string (i.e., an exact match), omit the % character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb395456",
   "metadata": {
    "id": "eb395456",
    "outputId": "d23db67f-161b-48c6-ab42-413a39ae5908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+\n",
      "|              author|               title|title LIKE % THE %|\n",
      "+--------------------+--------------------+------------------+\n",
      "|       Dean R Koontz|           ODD HOURS|             false|\n",
      "|     Stephenie Meyer|            THE HOST|             false|\n",
      "|        Emily Giffin|LOVE THE ONE YOU'...|              true|\n",
      "|   Patricia Cornwell|           THE FRONT|             false|\n",
      "|     Chuck Palahniuk|               SNUFF|             false|\n",
      "|James Patterson a...|SUNDAYS AT TIFFANY’S|             false|\n",
      "|       John Sandford|        PHANTOM PREY|             false|\n",
      "|       Jimmy Buffett|          SWINE NOT?|             false|\n",
      "|    Elizabeth George|     CARELESS IN RED|             false|\n",
      "|      David Baldacci|     THE WHOLE TRUTH|             false|\n",
      "|        Troy Denning|          INVINCIBLE|             false|\n",
      "|          James Frey|BRIGHT SHINY MORNING|             false|\n",
      "|         Garth Stein|THE ART OF RACING...|              true|\n",
      "|     Debbie Macomber|       TWENTY WISHES|             false|\n",
      "|         Jeff Shaara|      THE STEEL WAVE|             false|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show author and title, and whether the title contains the word \" THE \"\n",
    "df.select(\"author\", \"title\", df.title.like(\"% THE %\")).show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa737f01",
   "metadata": {
    "id": "fa737f01"
   },
   "source": [
    "### 3.4 startswith and endswith Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "223f0fb7",
   "metadata": {
    "id": "223f0fb7",
    "outputId": "6db585aa-53e6-4d66-875c-f65ca6d94110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------------+----------------------+\n",
      "|author           |title                   |startswith(title, THE)|\n",
      "+-----------------+------------------------+----------------------+\n",
      "|Dean R Koontz    |ODD HOURS               |false                 |\n",
      "|Stephenie Meyer  |THE HOST                |true                  |\n",
      "|Emily Giffin     |LOVE THE ONE YOU'RE WITH|false                 |\n",
      "|Patricia Cornwell|THE FRONT               |true                  |\n",
      "|Chuck Palahniuk  |SNUFF                   |false                 |\n",
      "+-----------------+------------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+------------------------+-------------------+\n",
      "|author           |title                   |endswith(title, NT)|\n",
      "+-----------------+------------------------+-------------------+\n",
      "|Dean R Koontz    |ODD HOURS               |false              |\n",
      "|Stephenie Meyer  |THE HOST                |false              |\n",
      "|Emily Giffin     |LOVE THE ONE YOU'RE WITH|false              |\n",
      "|Patricia Cornwell|THE FRONT               |true               |\n",
      "|Chuck Palahniuk  |SNUFF                   |false              |\n",
      "+-----------------+------------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"author\", \"title\", df.title.startswith(\"THE\")).show(5, truncate=False)\n",
    "df.select(\"author\", \"title\", df.title.endswith(\"NT\")).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861eee4",
   "metadata": {
    "id": "b861eee4"
   },
   "source": [
    "### 3.5 substring Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5ae1c23",
   "metadata": {
    "id": "d5ae1c23",
    "outputId": "e1ce0861-bd73-4712-99da-0608dcbd5024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|title|\n",
      "+-----+\n",
      "|  Dea|\n",
      "|  Ste|\n",
      "|  Emi|\n",
      "|  Pat|\n",
      "|  Chu|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|an R K|\n",
      "|epheni|\n",
      "|ily Gi|\n",
      "|tricia|\n",
      "|uck Pa|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+\n",
      "| title|\n",
      "+------+\n",
      "|Dean R|\n",
      "|Stephe|\n",
      "|Emily |\n",
      "|Patric|\n",
      "|Chuck |\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.author.substr(1, 3).alias(\"title\")).show(5)\n",
    "df.select(df.author.substr(3, 6).alias(\"title\")).show(5)\n",
    "df.select(df.author.substr(1, 6).alias(\"title\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bdcab1-322a-4d11-bf42-89c984f3c926",
   "metadata": {},
   "source": [
    "## 4. Join Operations\n",
    "https://pedropark99.github.io/Introd-pyspark/Chapters/08-transforming2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503539a0-6e94-498d-809a-69bd48748da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist's info:\n",
      "+------+--------------+----------+--------+\n",
      "|  name|          band|      born|children|\n",
      "+------+--------------+----------+--------+\n",
      "|  Mick|Rolling Stones|1943-07-26|    true|\n",
      "|  John|       Beatles|1940-09-10|    true|\n",
      "|  Paul|       Beatles|1942-06-18|    true|\n",
      "|George|       Beatles|1943-02-25|    true|\n",
      "| Ringo|       Beatles|1940-07-07|    true|\n",
      "+------+--------------+----------+--------+\n",
      "\n",
      "Instruments:\n",
      "+-----+------+\n",
      "| name| plays|\n",
      "+-----+------+\n",
      "| John|guitar|\n",
      "| Paul|  bass|\n",
      "|Keith|guitar|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "\n",
    "artists = [\n",
    "    ('Mick', 'Rolling Stones', '1943-07-26', True),\n",
    "    ('John', 'Beatles', '1940-09-10', True),\n",
    "    ('Paul', 'Beatles', '1942-06-18', True),\n",
    "    ('George', 'Beatles', '1943-02-25', True),\n",
    "    ('Ringo', 'Beatles', '1940-07-07', True)\n",
    "]\n",
    "\n",
    "artists_df = spark.createDataFrame(\n",
    "    artists,\n",
    "    ['name', 'band', 'born', 'children']\n",
    ")\n",
    "\n",
    "instruments = [\n",
    "    ('John', 'guitar'),\n",
    "    ('Paul', 'bass'),\n",
    "    ('Keith', 'guitar')\n",
    "]\n",
    "\n",
    "instruments_df = spark.createDataFrame(\n",
    "    instruments,\n",
    "    ['name', 'plays']\n",
    ")\n",
    "\n",
    "print(\"Artist's info:\")\n",
    "artists_df.show()\n",
    "print(\"Instruments:\")\n",
    "instruments_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ae641-6632-4b38-8a0d-23fe3e834072",
   "metadata": {},
   "source": [
    "### 4.1 Inner join (the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4f16750-7b6f-458b-9b48-54a3a9170412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+--------+------+\n",
      "|name|   band|      born|children| plays|\n",
      "+----+-------+----------+--------+------+\n",
      "|John|Beatles|1940-09-10|    true|guitar|\n",
      "|Paul|Beatles|1942-06-18|    true|  bass|\n",
      "+----+-------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(instruments_df, on = 'name', how = 'inner').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17be14bd-95c6-4823-ac0e-aa8c09383cbe",
   "metadata": {},
   "source": [
    "### 4.2 Left anti join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02289d42-9b27-45cd-b9d8-150060fba818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+--------+\n",
      "|  name|          band|      born|children|\n",
      "+------+--------------+----------+--------+\n",
      "|  Mick|Rolling Stones|1943-07-26|    true|\n",
      "|George|       Beatles|1943-02-25|    true|\n",
      "| Ringo|       Beatles|1940-07-07|    true|\n",
      "+------+--------------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(instruments_df, on = 'name', how = 'leftanti').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff9de91-2732-409d-bf4c-646b3c74e8e6",
   "metadata": {},
   "source": [
    "### 4.3 Left outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "247302aa-12f1-4db5-9c84-1a17677ca5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+--------+------+\n",
      "|  name|          band|      born|children| plays|\n",
      "+------+--------------+----------+--------+------+\n",
      "|  Mick|Rolling Stones|1943-07-26|    true|  NULL|\n",
      "|  John|       Beatles|1940-09-10|    true|guitar|\n",
      "|  Paul|       Beatles|1942-06-18|    true|  bass|\n",
      "|George|       Beatles|1943-02-25|    true|  NULL|\n",
      "| Ringo|       Beatles|1940-07-07|    true|  NULL|\n",
      "+------+--------------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(instruments_df, on = 'name', how = 'leftouter').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79144b0-dc10-4cbf-a278-95ab24db77aa",
   "metadata": {},
   "source": [
    "### 4.4 Right outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f24dabf0-62d9-46c6-850c-cb22202998c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----------+--------+------+\n",
      "| name|   band|      born|children| plays|\n",
      "+-----+-------+----------+--------+------+\n",
      "| John|Beatles|1940-09-10|    true|guitar|\n",
      "| Paul|Beatles|1942-06-18|    true|  bass|\n",
      "|Keith|   NULL|      NULL|    NULL|guitar|\n",
      "+-----+-------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(instruments_df, on = 'name', how = 'rightouter').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743f838-3811-48cd-b2bd-423db99e8023",
   "metadata": {},
   "source": [
    "### 4.5 Full outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8267a4c-6352-475e-87f1-0c3c40975639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+--------+------+\n",
      "|  name|          band|      born|children| plays|\n",
      "+------+--------------+----------+--------+------+\n",
      "|George|       Beatles|1943-02-25|    true|  NULL|\n",
      "|  John|       Beatles|1940-09-10|    true|guitar|\n",
      "| Keith|          NULL|      NULL|    NULL|guitar|\n",
      "|  Mick|Rolling Stones|1943-07-26|    true|  NULL|\n",
      "|  Paul|       Beatles|1942-06-18|    true|  bass|\n",
      "| Ringo|       Beatles|1940-07-07|    true|  NULL|\n",
      "+------+--------------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(instruments_df, on = 'name', how = 'fullouter').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88015f-e405-4763-9b68-579e71627f88",
   "metadata": {},
   "source": [
    "### 4.6 Left Semi Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58319af9-fc32-489d-9763-e9d886539fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+--------+\n",
      "|name|   band|      born|children|\n",
      "+----+-------+----------+--------+\n",
      "|John|Beatles|1940-09-10|    true|\n",
      "|Paul|Beatles|1942-06-18|    true|\n",
      "+----+-------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.join(instruments_df, on = 'name', how = 'leftsemi').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd203afe-e25e-48ee-84db-b1f4bd5547ed",
   "metadata": {},
   "source": [
    "### 4.7 Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4997d6d-e76c-4074-b7bf-ae197c4b88cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:============================================>        (111 + 16) / 131]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+--------+-----+------+\n",
      "|  name|          band|      born|children| name| plays|\n",
      "+------+--------------+----------+--------+-----+------+\n",
      "|  Mick|Rolling Stones|1943-07-26|    true| John|guitar|\n",
      "|  Mick|Rolling Stones|1943-07-26|    true| Paul|  bass|\n",
      "|  Mick|Rolling Stones|1943-07-26|    true|Keith|guitar|\n",
      "|  John|       Beatles|1940-09-10|    true| John|guitar|\n",
      "|  John|       Beatles|1940-09-10|    true| Paul|  bass|\n",
      "|  John|       Beatles|1940-09-10|    true|Keith|guitar|\n",
      "|  Paul|       Beatles|1942-06-18|    true| John|guitar|\n",
      "|  Paul|       Beatles|1942-06-18|    true| Paul|  bass|\n",
      "|  Paul|       Beatles|1942-06-18|    true|Keith|guitar|\n",
      "|George|       Beatles|1943-02-25|    true| John|guitar|\n",
      "|George|       Beatles|1943-02-25|    true| Paul|  bass|\n",
      "|George|       Beatles|1943-02-25|    true|Keith|guitar|\n",
      "| Ringo|       Beatles|1940-07-07|    true| John|guitar|\n",
      "| Ringo|       Beatles|1940-07-07|    true| Paul|  bass|\n",
      "| Ringo|       Beatles|1940-07-07|    true|Keith|guitar|\n",
      "+------+--------------+----------+--------+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "artists_df.crossJoin(instruments_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c17df05",
   "metadata": {
    "id": "2c17df05"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
