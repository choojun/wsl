# PRACTICAL 3.0: PySpark Environment

0. Launch the setup Ubuntu-xx.xx distro using PowerShell. Subsequently, log in as the user hduser and start HDFS and YARN services.

1. Login as the user student.

   1.1 Add Spark-related variables to studentâ€™s profile using command, i.e. nano ~/.profile, and add the following environment variables (IF NOT EXIST) to the end of the file.
   ~~~bash
   export SPARK_HOME=/home/hduser/spark
   export PATH=$PATH:$SPARK_HOME/bin
   ~~~

   1.2 Source the ~/.profile file
   ~~~bash
   student@MyPC:~$ source ~/.profile
   ~~~
   
2. Test it using the PySpark Interactive Shell: Word count example

   2.1 Launch the PySpark interactive shell
      ~~~bash
      student@MyPC:~$ pyspark
      ~~~
      > You should be able to observe the response on screen, indicating the version of Spark installed.


# End of Practical

If no more activity using Spark or Hadoop, remember to stop the YARN service followed by the HDFS service.


